{"version":3,"file":"875.index.js","mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":[".././node_modules/.pnpm/@aws-sdk+credential-provider-http@3.966.0/node_modules/@aws-sdk/credential-provider-http/dist-cjs/fromHttp/checkUrl.js",".././node_modules/.pnpm/@aws-sdk+credential-provider-http@3.966.0/node_modules/@aws-sdk/credential-provider-http/dist-cjs/fromHttp/fromHttp.js",".././node_modules/.pnpm/@aws-sdk+credential-provider-http@3.966.0/node_modules/@aws-sdk/credential-provider-http/dist-cjs/fromHttp/requestHelpers.js",".././node_modules/.pnpm/@aws-sdk+credential-provider-http@3.966.0/node_modules/@aws-sdk/credential-provider-http/dist-cjs/fromHttp/retry-wrapper.js",".././node_modules/.pnpm/@aws-sdk+credential-provider-http@3.966.0/node_modules/@aws-sdk/credential-provider-http/dist-cjs/index.js",".././node_modules/.pnpm/@smithy+fetch-http-handler@5.3.8/node_modules/@smithy/fetch-http-handler/dist-cjs/index.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/ByteArrayCollector.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/checksum/ChecksumStream.browser.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/checksum/ChecksumStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/checksum/createChecksumStream.browser.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/checksum/createChecksumStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/createBufferedReadable.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/createBufferedReadableStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/getAwsChunkedEncodingStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/headStream.browser.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/headStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/index.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/sdk-stream-mixin.browser.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/sdk-stream-mixin.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/splitStream.browser.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/splitStream.js",".././node_modules/.pnpm/@smithy+util-stream@4.5.8/node_modules/@smithy/util-stream/dist-cjs/stream-type-check.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.checkUrl = void 0;\nconst property_provider_1 = require(\"@smithy/property-provider\");\nconst LOOPBACK_CIDR_IPv4 = \"127.0.0.0/8\";\nconst LOOPBACK_CIDR_IPv6 = \"::1/128\";\nconst ECS_CONTAINER_HOST = \"169.254.170.2\";\nconst EKS_CONTAINER_HOST_IPv4 = \"169.254.170.23\";\nconst EKS_CONTAINER_HOST_IPv6 = \"[fd00:ec2::23]\";\nconst checkUrl = (url, logger) => {\n    if (url.protocol === \"https:\") {\n        return;\n    }\n    if (url.hostname === ECS_CONTAINER_HOST ||\n        url.hostname === EKS_CONTAINER_HOST_IPv4 ||\n        url.hostname === EKS_CONTAINER_HOST_IPv6) {\n        return;\n    }\n    if (url.hostname.includes(\"[\")) {\n        if (url.hostname === \"[::1]\" || url.hostname === \"[0000:0000:0000:0000:0000:0000:0000:0001]\") {\n            return;\n        }\n    }\n    else {\n        if (url.hostname === \"localhost\") {\n            return;\n        }\n        const ipComponents = url.hostname.split(\".\");\n        const inRange = (component) => {\n            const num = parseInt(component, 10);\n            return 0 <= num && num <= 255;\n        };\n        if (ipComponents[0] === \"127\" &&\n            inRange(ipComponents[1]) &&\n            inRange(ipComponents[2]) &&\n            inRange(ipComponents[3]) &&\n            ipComponents.length === 4) {\n            return;\n        }\n    }\n    throw new property_provider_1.CredentialsProviderError(`URL not accepted. It must either be HTTPS or match one of the following:\n  - loopback CIDR 127.0.0.0/8 or [::1/128]\n  - ECS container host 169.254.170.2\n  - EKS container host 169.254.170.23 or [fd00:ec2::23]`, { logger });\n};\nexports.checkUrl = checkUrl;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromHttp = void 0;\nconst tslib_1 = require(\"tslib\");\nconst client_1 = require(\"@aws-sdk/core/client\");\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst property_provider_1 = require(\"@smithy/property-provider\");\nconst promises_1 = tslib_1.__importDefault(require(\"fs/promises\"));\nconst checkUrl_1 = require(\"./checkUrl\");\nconst requestHelpers_1 = require(\"./requestHelpers\");\nconst retry_wrapper_1 = require(\"./retry-wrapper\");\nconst AWS_CONTAINER_CREDENTIALS_RELATIVE_URI = \"AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\";\nconst DEFAULT_LINK_LOCAL_HOST = \"http://169.254.170.2\";\nconst AWS_CONTAINER_CREDENTIALS_FULL_URI = \"AWS_CONTAINER_CREDENTIALS_FULL_URI\";\nconst AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE = \"AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE\";\nconst AWS_CONTAINER_AUTHORIZATION_TOKEN = \"AWS_CONTAINER_AUTHORIZATION_TOKEN\";\nconst fromHttp = (options = {}) => {\n    options.logger?.debug(\"@aws-sdk/credential-provider-http - fromHttp\");\n    let host;\n    const relative = options.awsContainerCredentialsRelativeUri ?? process.env[AWS_CONTAINER_CREDENTIALS_RELATIVE_URI];\n    const full = options.awsContainerCredentialsFullUri ?? process.env[AWS_CONTAINER_CREDENTIALS_FULL_URI];\n    const token = options.awsContainerAuthorizationToken ?? process.env[AWS_CONTAINER_AUTHORIZATION_TOKEN];\n    const tokenFile = options.awsContainerAuthorizationTokenFile ?? process.env[AWS_CONTAINER_AUTHORIZATION_TOKEN_FILE];\n    const warn = options.logger?.constructor?.name === \"NoOpLogger\" || !options.logger?.warn\n        ? console.warn\n        : options.logger.warn.bind(options.logger);\n    if (relative && full) {\n        warn(\"@aws-sdk/credential-provider-http: \" +\n            \"you have set both awsContainerCredentialsRelativeUri and awsContainerCredentialsFullUri.\");\n        warn(\"awsContainerCredentialsFullUri will take precedence.\");\n    }\n    if (token && tokenFile) {\n        warn(\"@aws-sdk/credential-provider-http: \" +\n            \"you have set both awsContainerAuthorizationToken and awsContainerAuthorizationTokenFile.\");\n        warn(\"awsContainerAuthorizationToken will take precedence.\");\n    }\n    if (full) {\n        host = full;\n    }\n    else if (relative) {\n        host = `${DEFAULT_LINK_LOCAL_HOST}${relative}`;\n    }\n    else {\n        throw new property_provider_1.CredentialsProviderError(`No HTTP credential provider host provided.\nSet AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI.`, { logger: options.logger });\n    }\n    const url = new URL(host);\n    (0, checkUrl_1.checkUrl)(url, options.logger);\n    const requestHandler = node_http_handler_1.NodeHttpHandler.create({\n        requestTimeout: options.timeout ?? 1000,\n        connectionTimeout: options.timeout ?? 1000,\n    });\n    return (0, retry_wrapper_1.retryWrapper)(async () => {\n        const request = (0, requestHelpers_1.createGetRequest)(url);\n        if (token) {\n            request.headers.Authorization = token;\n        }\n        else if (tokenFile) {\n            request.headers.Authorization = (await promises_1.default.readFile(tokenFile)).toString();\n        }\n        try {\n            const result = await requestHandler.handle(request);\n            return (0, requestHelpers_1.getCredentials)(result.response).then((creds) => (0, client_1.setCredentialFeature)(creds, \"CREDENTIALS_HTTP\", \"z\"));\n        }\n        catch (e) {\n            throw new property_provider_1.CredentialsProviderError(String(e), { logger: options.logger });\n        }\n    }, options.maxRetries ?? 3, options.timeout ?? 1000);\n};\nexports.fromHttp = fromHttp;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createGetRequest = createGetRequest;\nexports.getCredentials = getCredentials;\nconst property_provider_1 = require(\"@smithy/property-provider\");\nconst protocol_http_1 = require(\"@smithy/protocol-http\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst util_stream_1 = require(\"@smithy/util-stream\");\nfunction createGetRequest(url) {\n    return new protocol_http_1.HttpRequest({\n        protocol: url.protocol,\n        hostname: url.hostname,\n        port: Number(url.port),\n        path: url.pathname,\n        query: Array.from(url.searchParams.entries()).reduce((acc, [k, v]) => {\n            acc[k] = v;\n            return acc;\n        }, {}),\n        fragment: url.hash,\n    });\n}\nasync function getCredentials(response, logger) {\n    const stream = (0, util_stream_1.sdkStreamMixin)(response.body);\n    const str = await stream.transformToString();\n    if (response.statusCode === 200) {\n        const parsed = JSON.parse(str);\n        if (typeof parsed.AccessKeyId !== \"string\" ||\n            typeof parsed.SecretAccessKey !== \"string\" ||\n            typeof parsed.Token !== \"string\" ||\n            typeof parsed.Expiration !== \"string\") {\n            throw new property_provider_1.CredentialsProviderError(\"HTTP credential provider response not of the required format, an object matching: \" +\n                \"{ AccessKeyId: string, SecretAccessKey: string, Token: string, Expiration: string(rfc3339) }\", { logger });\n        }\n        return {\n            accessKeyId: parsed.AccessKeyId,\n            secretAccessKey: parsed.SecretAccessKey,\n            sessionToken: parsed.Token,\n            expiration: (0, smithy_client_1.parseRfc3339DateTime)(parsed.Expiration),\n        };\n    }\n    if (response.statusCode >= 400 && response.statusCode < 500) {\n        let parsedBody = {};\n        try {\n            parsedBody = JSON.parse(str);\n        }\n        catch (e) { }\n        throw Object.assign(new property_provider_1.CredentialsProviderError(`Server responded with status: ${response.statusCode}`, { logger }), {\n            Code: parsedBody.Code,\n            Message: parsedBody.Message,\n        });\n    }\n    throw new property_provider_1.CredentialsProviderError(`Server responded with status: ${response.statusCode}`, { logger });\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.retryWrapper = void 0;\nconst retryWrapper = (toRetry, maxRetries, delayMs) => {\n    return async () => {\n        for (let i = 0; i < maxRetries; ++i) {\n            try {\n                return await toRetry();\n            }\n            catch (e) {\n                await new Promise((resolve) => setTimeout(resolve, delayMs));\n            }\n        }\n        return await toRetry();\n    };\n};\nexports.retryWrapper = retryWrapper;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromHttp = void 0;\nvar fromHttp_1 = require(\"./fromHttp/fromHttp\");\nObject.defineProperty(exports, \"fromHttp\", { enumerable: true, get: function () { return fromHttp_1.fromHttp; } });\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar querystringBuilder = require('@smithy/querystring-builder');\nvar utilBase64 = require('@smithy/util-base64');\n\nfunction createRequest(url, requestOptions) {\n    return new Request(url, requestOptions);\n}\n\nfunction requestTimeout(timeoutInMs = 0) {\n    return new Promise((resolve, reject) => {\n        if (timeoutInMs) {\n            setTimeout(() => {\n                const timeoutError = new Error(`Request did not complete within ${timeoutInMs} ms`);\n                timeoutError.name = \"TimeoutError\";\n                reject(timeoutError);\n            }, timeoutInMs);\n        }\n    });\n}\n\nconst keepAliveSupport = {\n    supported: undefined,\n};\nclass FetchHttpHandler {\n    config;\n    configProvider;\n    static create(instanceOrOptions) {\n        if (typeof instanceOrOptions?.handle === \"function\") {\n            return instanceOrOptions;\n        }\n        return new FetchHttpHandler(instanceOrOptions);\n    }\n    constructor(options) {\n        if (typeof options === \"function\") {\n            this.configProvider = options().then((opts) => opts || {});\n        }\n        else {\n            this.config = options ?? {};\n            this.configProvider = Promise.resolve(this.config);\n        }\n        if (keepAliveSupport.supported === undefined) {\n            keepAliveSupport.supported = Boolean(typeof Request !== \"undefined\" && \"keepalive\" in createRequest(\"https://[::1]\"));\n        }\n    }\n    destroy() {\n    }\n    async handle(request, { abortSignal, requestTimeout: requestTimeout$1 } = {}) {\n        if (!this.config) {\n            this.config = await this.configProvider;\n        }\n        const requestTimeoutInMs = requestTimeout$1 ?? this.config.requestTimeout;\n        const keepAlive = this.config.keepAlive === true;\n        const credentials = this.config.credentials;\n        if (abortSignal?.aborted) {\n            const abortError = new Error(\"Request aborted\");\n            abortError.name = \"AbortError\";\n            return Promise.reject(abortError);\n        }\n        let path = request.path;\n        const queryString = querystringBuilder.buildQueryString(request.query || {});\n        if (queryString) {\n            path += `?${queryString}`;\n        }\n        if (request.fragment) {\n            path += `#${request.fragment}`;\n        }\n        let auth = \"\";\n        if (request.username != null || request.password != null) {\n            const username = request.username ?? \"\";\n            const password = request.password ?? \"\";\n            auth = `${username}:${password}@`;\n        }\n        const { port, method } = request;\n        const url = `${request.protocol}//${auth}${request.hostname}${port ? `:${port}` : \"\"}${path}`;\n        const body = method === \"GET\" || method === \"HEAD\" ? undefined : request.body;\n        const requestOptions = {\n            body,\n            headers: new Headers(request.headers),\n            method: method,\n            credentials,\n        };\n        if (this.config?.cache) {\n            requestOptions.cache = this.config.cache;\n        }\n        if (body) {\n            requestOptions.duplex = \"half\";\n        }\n        if (typeof AbortController !== \"undefined\") {\n            requestOptions.signal = abortSignal;\n        }\n        if (keepAliveSupport.supported) {\n            requestOptions.keepalive = keepAlive;\n        }\n        if (typeof this.config.requestInit === \"function\") {\n            Object.assign(requestOptions, this.config.requestInit(request));\n        }\n        let removeSignalEventListener = () => { };\n        const fetchRequest = createRequest(url, requestOptions);\n        const raceOfPromises = [\n            fetch(fetchRequest).then((response) => {\n                const fetchHeaders = response.headers;\n                const transformedHeaders = {};\n                for (const pair of fetchHeaders.entries()) {\n                    transformedHeaders[pair[0]] = pair[1];\n                }\n                const hasReadableStream = response.body != undefined;\n                if (!hasReadableStream) {\n                    return response.blob().then((body) => ({\n                        response: new protocolHttp.HttpResponse({\n                            headers: transformedHeaders,\n                            reason: response.statusText,\n                            statusCode: response.status,\n                            body,\n                        }),\n                    }));\n                }\n                return {\n                    response: new protocolHttp.HttpResponse({\n                        headers: transformedHeaders,\n                        reason: response.statusText,\n                        statusCode: response.status,\n                        body: response.body,\n                    }),\n                };\n            }),\n            requestTimeout(requestTimeoutInMs),\n        ];\n        if (abortSignal) {\n            raceOfPromises.push(new Promise((resolve, reject) => {\n                const onAbort = () => {\n                    const abortError = new Error(\"Request aborted\");\n                    abortError.name = \"AbortError\";\n                    reject(abortError);\n                };\n                if (typeof abortSignal.addEventListener === \"function\") {\n                    const signal = abortSignal;\n                    signal.addEventListener(\"abort\", onAbort, { once: true });\n                    removeSignalEventListener = () => signal.removeEventListener(\"abort\", onAbort);\n                }\n                else {\n                    abortSignal.onabort = onAbort;\n                }\n            }));\n        }\n        return Promise.race(raceOfPromises).finally(removeSignalEventListener);\n    }\n    updateHttpClientConfig(key, value) {\n        this.config = undefined;\n        this.configProvider = this.configProvider.then((config) => {\n            config[key] = value;\n            return config;\n        });\n    }\n    httpHandlerConfigs() {\n        return this.config ?? {};\n    }\n}\n\nconst streamCollector = async (stream) => {\n    if ((typeof Blob === \"function\" && stream instanceof Blob) || stream.constructor?.name === \"Blob\") {\n        if (Blob.prototype.arrayBuffer !== undefined) {\n            return new Uint8Array(await stream.arrayBuffer());\n        }\n        return collectBlob(stream);\n    }\n    return collectStream(stream);\n};\nasync function collectBlob(blob) {\n    const base64 = await readToBase64(blob);\n    const arrayBuffer = utilBase64.fromBase64(base64);\n    return new Uint8Array(arrayBuffer);\n}\nasync function collectStream(stream) {\n    const chunks = [];\n    const reader = stream.getReader();\n    let isDone = false;\n    let length = 0;\n    while (!isDone) {\n        const { done, value } = await reader.read();\n        if (value) {\n            chunks.push(value);\n            length += value.length;\n        }\n        isDone = done;\n    }\n    const collected = new Uint8Array(length);\n    let offset = 0;\n    for (const chunk of chunks) {\n        collected.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return collected;\n}\nfunction readToBase64(blob) {\n    return new Promise((resolve, reject) => {\n        const reader = new FileReader();\n        reader.onloadend = () => {\n            if (reader.readyState !== 2) {\n                return reject(new Error(\"Reader aborted too early\"));\n            }\n            const result = (reader.result ?? \"\");\n            const commaIndex = result.indexOf(\",\");\n            const dataOffset = commaIndex > -1 ? commaIndex + 1 : result.length;\n            resolve(result.substring(dataOffset));\n        };\n        reader.onabort = () => reject(new Error(\"Read aborted\"));\n        reader.onerror = () => reject(reader.error);\n        reader.readAsDataURL(blob);\n    });\n}\n\nexports.FetchHttpHandler = FetchHttpHandler;\nexports.keepAliveSupport = keepAliveSupport;\nexports.streamCollector = streamCollector;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ByteArrayCollector = void 0;\nclass ByteArrayCollector {\n    allocByteArray;\n    byteLength = 0;\n    byteArrays = [];\n    constructor(allocByteArray) {\n        this.allocByteArray = allocByteArray;\n    }\n    push(byteArray) {\n        this.byteArrays.push(byteArray);\n        this.byteLength += byteArray.byteLength;\n    }\n    flush() {\n        if (this.byteArrays.length === 1) {\n            const bytes = this.byteArrays[0];\n            this.reset();\n            return bytes;\n        }\n        const aggregation = this.allocByteArray(this.byteLength);\n        let cursor = 0;\n        for (let i = 0; i < this.byteArrays.length; ++i) {\n            const bytes = this.byteArrays[i];\n            aggregation.set(bytes, cursor);\n            cursor += bytes.byteLength;\n        }\n        this.reset();\n        return aggregation;\n    }\n    reset() {\n        this.byteArrays = [];\n        this.byteLength = 0;\n    }\n}\nexports.ByteArrayCollector = ByteArrayCollector;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ChecksumStream = void 0;\nconst ReadableStreamRef = typeof ReadableStream === \"function\" ? ReadableStream : function () { };\nclass ChecksumStream extends ReadableStreamRef {\n}\nexports.ChecksumStream = ChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ChecksumStream = void 0;\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst stream_1 = require(\"stream\");\nclass ChecksumStream extends stream_1.Duplex {\n    expectedChecksum;\n    checksumSourceLocation;\n    checksum;\n    source;\n    base64Encoder;\n    constructor({ expectedChecksum, checksum, source, checksumSourceLocation, base64Encoder, }) {\n        super();\n        if (typeof source.pipe === \"function\") {\n            this.source = source;\n        }\n        else {\n            throw new Error(`@smithy/util-stream: unsupported source type ${source?.constructor?.name ?? source} in ChecksumStream.`);\n        }\n        this.base64Encoder = base64Encoder ?? util_base64_1.toBase64;\n        this.expectedChecksum = expectedChecksum;\n        this.checksum = checksum;\n        this.checksumSourceLocation = checksumSourceLocation;\n        this.source.pipe(this);\n    }\n    _read(size) { }\n    _write(chunk, encoding, callback) {\n        try {\n            this.checksum.update(chunk);\n            this.push(chunk);\n        }\n        catch (e) {\n            return callback(e);\n        }\n        return callback();\n    }\n    async _final(callback) {\n        try {\n            const digest = await this.checksum.digest();\n            const received = this.base64Encoder(digest);\n            if (this.expectedChecksum !== received) {\n                return callback(new Error(`Checksum mismatch: expected \"${this.expectedChecksum}\" but received \"${received}\"` +\n                    ` in response header \"${this.checksumSourceLocation}\".`));\n            }\n        }\n        catch (e) {\n            return callback(e);\n        }\n        this.push(null);\n        return callback();\n    }\n}\nexports.ChecksumStream = ChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createChecksumStream = void 0;\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst stream_type_check_1 = require(\"../stream-type-check\");\nconst ChecksumStream_browser_1 = require(\"./ChecksumStream.browser\");\nconst createChecksumStream = ({ expectedChecksum, checksum, source, checksumSourceLocation, base64Encoder, }) => {\n    if (!(0, stream_type_check_1.isReadableStream)(source)) {\n        throw new Error(`@smithy/util-stream: unsupported source type ${source?.constructor?.name ?? source} in ChecksumStream.`);\n    }\n    const encoder = base64Encoder ?? util_base64_1.toBase64;\n    if (typeof TransformStream !== \"function\") {\n        throw new Error(\"@smithy/util-stream: unable to instantiate ChecksumStream because API unavailable: ReadableStream/TransformStream.\");\n    }\n    const transform = new TransformStream({\n        start() { },\n        async transform(chunk, controller) {\n            checksum.update(chunk);\n            controller.enqueue(chunk);\n        },\n        async flush(controller) {\n            const digest = await checksum.digest();\n            const received = encoder(digest);\n            if (expectedChecksum !== received) {\n                const error = new Error(`Checksum mismatch: expected \"${expectedChecksum}\" but received \"${received}\"` +\n                    ` in response header \"${checksumSourceLocation}\".`);\n                controller.error(error);\n            }\n            else {\n                controller.terminate();\n            }\n        },\n    });\n    source.pipeThrough(transform);\n    const readable = transform.readable;\n    Object.setPrototypeOf(readable, ChecksumStream_browser_1.ChecksumStream.prototype);\n    return readable;\n};\nexports.createChecksumStream = createChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createChecksumStream = createChecksumStream;\nconst stream_type_check_1 = require(\"../stream-type-check\");\nconst ChecksumStream_1 = require(\"./ChecksumStream\");\nconst createChecksumStream_browser_1 = require(\"./createChecksumStream.browser\");\nfunction createChecksumStream(init) {\n    if (typeof ReadableStream === \"function\" && (0, stream_type_check_1.isReadableStream)(init.source)) {\n        return (0, createChecksumStream_browser_1.createChecksumStream)(init);\n    }\n    return new ChecksumStream_1.ChecksumStream(init);\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createBufferedReadable = createBufferedReadable;\nconst node_stream_1 = require(\"node:stream\");\nconst ByteArrayCollector_1 = require(\"./ByteArrayCollector\");\nconst createBufferedReadableStream_1 = require(\"./createBufferedReadableStream\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nfunction createBufferedReadable(upstream, size, logger) {\n    if ((0, stream_type_check_1.isReadableStream)(upstream)) {\n        return (0, createBufferedReadableStream_1.createBufferedReadableStream)(upstream, size, logger);\n    }\n    const downstream = new node_stream_1.Readable({ read() { } });\n    let streamBufferingLoggedWarning = false;\n    let bytesSeen = 0;\n    const buffers = [\n        \"\",\n        new ByteArrayCollector_1.ByteArrayCollector((size) => new Uint8Array(size)),\n        new ByteArrayCollector_1.ByteArrayCollector((size) => Buffer.from(new Uint8Array(size))),\n    ];\n    let mode = -1;\n    upstream.on(\"data\", (chunk) => {\n        const chunkMode = (0, createBufferedReadableStream_1.modeOf)(chunk, true);\n        if (mode !== chunkMode) {\n            if (mode >= 0) {\n                downstream.push((0, createBufferedReadableStream_1.flush)(buffers, mode));\n            }\n            mode = chunkMode;\n        }\n        if (mode === -1) {\n            downstream.push(chunk);\n            return;\n        }\n        const chunkSize = (0, createBufferedReadableStream_1.sizeOf)(chunk);\n        bytesSeen += chunkSize;\n        const bufferSize = (0, createBufferedReadableStream_1.sizeOf)(buffers[mode]);\n        if (chunkSize >= size && bufferSize === 0) {\n            downstream.push(chunk);\n        }\n        else {\n            const newSize = (0, createBufferedReadableStream_1.merge)(buffers, mode, chunk);\n            if (!streamBufferingLoggedWarning && bytesSeen > size * 2) {\n                streamBufferingLoggedWarning = true;\n                logger?.warn(`@smithy/util-stream - stream chunk size ${chunkSize} is below threshold of ${size}, automatically buffering.`);\n            }\n            if (newSize >= size) {\n                downstream.push((0, createBufferedReadableStream_1.flush)(buffers, mode));\n            }\n        }\n    });\n    upstream.on(\"end\", () => {\n        if (mode !== -1) {\n            const remainder = (0, createBufferedReadableStream_1.flush)(buffers, mode);\n            if ((0, createBufferedReadableStream_1.sizeOf)(remainder) > 0) {\n                downstream.push(remainder);\n            }\n        }\n        downstream.push(null);\n    });\n    return downstream;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createBufferedReadable = void 0;\nexports.createBufferedReadableStream = createBufferedReadableStream;\nexports.merge = merge;\nexports.flush = flush;\nexports.sizeOf = sizeOf;\nexports.modeOf = modeOf;\nconst ByteArrayCollector_1 = require(\"./ByteArrayCollector\");\nfunction createBufferedReadableStream(upstream, size, logger) {\n    const reader = upstream.getReader();\n    let streamBufferingLoggedWarning = false;\n    let bytesSeen = 0;\n    const buffers = [\"\", new ByteArrayCollector_1.ByteArrayCollector((size) => new Uint8Array(size))];\n    let mode = -1;\n    const pull = async (controller) => {\n        const { value, done } = await reader.read();\n        const chunk = value;\n        if (done) {\n            if (mode !== -1) {\n                const remainder = flush(buffers, mode);\n                if (sizeOf(remainder) > 0) {\n                    controller.enqueue(remainder);\n                }\n            }\n            controller.close();\n        }\n        else {\n            const chunkMode = modeOf(chunk, false);\n            if (mode !== chunkMode) {\n                if (mode >= 0) {\n                    controller.enqueue(flush(buffers, mode));\n                }\n                mode = chunkMode;\n            }\n            if (mode === -1) {\n                controller.enqueue(chunk);\n                return;\n            }\n            const chunkSize = sizeOf(chunk);\n            bytesSeen += chunkSize;\n            const bufferSize = sizeOf(buffers[mode]);\n            if (chunkSize >= size && bufferSize === 0) {\n                controller.enqueue(chunk);\n            }\n            else {\n                const newSize = merge(buffers, mode, chunk);\n                if (!streamBufferingLoggedWarning && bytesSeen > size * 2) {\n                    streamBufferingLoggedWarning = true;\n                    logger?.warn(`@smithy/util-stream - stream chunk size ${chunkSize} is below threshold of ${size}, automatically buffering.`);\n                }\n                if (newSize >= size) {\n                    controller.enqueue(flush(buffers, mode));\n                }\n                else {\n                    await pull(controller);\n                }\n            }\n        }\n    };\n    return new ReadableStream({\n        pull,\n    });\n}\nexports.createBufferedReadable = createBufferedReadableStream;\nfunction merge(buffers, mode, chunk) {\n    switch (mode) {\n        case 0:\n            buffers[0] += chunk;\n            return sizeOf(buffers[0]);\n        case 1:\n        case 2:\n            buffers[mode].push(chunk);\n            return sizeOf(buffers[mode]);\n    }\n}\nfunction flush(buffers, mode) {\n    switch (mode) {\n        case 0:\n            const s = buffers[0];\n            buffers[0] = \"\";\n            return s;\n        case 1:\n        case 2:\n            return buffers[mode].flush();\n    }\n    throw new Error(`@smithy/util-stream - invalid index ${mode} given to flush()`);\n}\nfunction sizeOf(chunk) {\n    return chunk?.byteLength ?? chunk?.length ?? 0;\n}\nfunction modeOf(chunk, allowBuffer = true) {\n    if (allowBuffer && typeof Buffer !== \"undefined\" && chunk instanceof Buffer) {\n        return 2;\n    }\n    if (chunk instanceof Uint8Array) {\n        return 1;\n    }\n    if (typeof chunk === \"string\") {\n        return 0;\n    }\n    return -1;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAwsChunkedEncodingStream = void 0;\nconst stream_1 = require(\"stream\");\nconst getAwsChunkedEncodingStream = (readableStream, options) => {\n    const { base64Encoder, bodyLengthChecker, checksumAlgorithmFn, checksumLocationName, streamHasher } = options;\n    const checksumRequired = base64Encoder !== undefined &&\n        checksumAlgorithmFn !== undefined &&\n        checksumLocationName !== undefined &&\n        streamHasher !== undefined;\n    const digest = checksumRequired ? streamHasher(checksumAlgorithmFn, readableStream) : undefined;\n    const awsChunkedEncodingStream = new stream_1.Readable({ read: () => { } });\n    readableStream.on(\"data\", (data) => {\n        const length = bodyLengthChecker(data) || 0;\n        awsChunkedEncodingStream.push(`${length.toString(16)}\\r\\n`);\n        awsChunkedEncodingStream.push(data);\n        awsChunkedEncodingStream.push(\"\\r\\n\");\n    });\n    readableStream.on(\"end\", async () => {\n        awsChunkedEncodingStream.push(`0\\r\\n`);\n        if (checksumRequired) {\n            const checksum = base64Encoder(await digest);\n            awsChunkedEncodingStream.push(`${checksumLocationName}:${checksum}\\r\\n`);\n            awsChunkedEncodingStream.push(`\\r\\n`);\n        }\n        awsChunkedEncodingStream.push(null);\n    });\n    return awsChunkedEncodingStream;\n};\nexports.getAwsChunkedEncodingStream = getAwsChunkedEncodingStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.headStream = headStream;\nasync function headStream(stream, bytes) {\n    let byteLengthCounter = 0;\n    const chunks = [];\n    const reader = stream.getReader();\n    let isDone = false;\n    while (!isDone) {\n        const { done, value } = await reader.read();\n        if (value) {\n            chunks.push(value);\n            byteLengthCounter += value?.byteLength ?? 0;\n        }\n        if (byteLengthCounter >= bytes) {\n            break;\n        }\n        isDone = done;\n    }\n    reader.releaseLock();\n    const collected = new Uint8Array(Math.min(bytes, byteLengthCounter));\n    let offset = 0;\n    for (const chunk of chunks) {\n        if (chunk.byteLength > collected.byteLength - offset) {\n            collected.set(chunk.subarray(0, collected.byteLength - offset), offset);\n            break;\n        }\n        else {\n            collected.set(chunk, offset);\n        }\n        offset += chunk.length;\n    }\n    return collected;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.headStream = void 0;\nconst stream_1 = require(\"stream\");\nconst headStream_browser_1 = require(\"./headStream.browser\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nconst headStream = (stream, bytes) => {\n    if ((0, stream_type_check_1.isReadableStream)(stream)) {\n        return (0, headStream_browser_1.headStream)(stream, bytes);\n    }\n    return new Promise((resolve, reject) => {\n        const collector = new Collector();\n        collector.limit = bytes;\n        stream.pipe(collector);\n        stream.on(\"error\", (err) => {\n            collector.end();\n            reject(err);\n        });\n        collector.on(\"error\", reject);\n        collector.on(\"finish\", function () {\n            const bytes = new Uint8Array(Buffer.concat(this.buffers));\n            resolve(bytes);\n        });\n    });\n};\nexports.headStream = headStream;\nclass Collector extends stream_1.Writable {\n    buffers = [];\n    limit = Infinity;\n    bytesBuffered = 0;\n    _write(chunk, encoding, callback) {\n        this.buffers.push(chunk);\n        this.bytesBuffered += chunk.byteLength ?? 0;\n        if (this.bytesBuffered >= this.limit) {\n            const excess = this.bytesBuffered - this.limit;\n            const tailBuffer = this.buffers[this.buffers.length - 1];\n            this.buffers[this.buffers.length - 1] = tailBuffer.subarray(0, tailBuffer.byteLength - excess);\n            this.emit(\"finish\");\n        }\n        callback();\n    }\n}\n","'use strict';\n\nvar utilBase64 = require('@smithy/util-base64');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar ChecksumStream = require('./checksum/ChecksumStream');\nvar createChecksumStream = require('./checksum/createChecksumStream');\nvar createBufferedReadable = require('./createBufferedReadable');\nvar getAwsChunkedEncodingStream = require('./getAwsChunkedEncodingStream');\nvar headStream = require('./headStream');\nvar sdkStreamMixin = require('./sdk-stream-mixin');\nvar splitStream = require('./splitStream');\nvar streamTypeCheck = require('./stream-type-check');\n\nclass Uint8ArrayBlobAdapter extends Uint8Array {\n    static fromString(source, encoding = \"utf-8\") {\n        if (typeof source === \"string\") {\n            if (encoding === \"base64\") {\n                return Uint8ArrayBlobAdapter.mutate(utilBase64.fromBase64(source));\n            }\n            return Uint8ArrayBlobAdapter.mutate(utilUtf8.fromUtf8(source));\n        }\n        throw new Error(`Unsupported conversion from ${typeof source} to Uint8ArrayBlobAdapter.`);\n    }\n    static mutate(source) {\n        Object.setPrototypeOf(source, Uint8ArrayBlobAdapter.prototype);\n        return source;\n    }\n    transformToString(encoding = \"utf-8\") {\n        if (encoding === \"base64\") {\n            return utilBase64.toBase64(this);\n        }\n        return utilUtf8.toUtf8(this);\n    }\n}\n\nexports.Uint8ArrayBlobAdapter = Uint8ArrayBlobAdapter;\nObject.keys(ChecksumStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return ChecksumStream[k]; }\n    });\n});\nObject.keys(createChecksumStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return createChecksumStream[k]; }\n    });\n});\nObject.keys(createBufferedReadable).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return createBufferedReadable[k]; }\n    });\n});\nObject.keys(getAwsChunkedEncodingStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return getAwsChunkedEncodingStream[k]; }\n    });\n});\nObject.keys(headStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return headStream[k]; }\n    });\n});\nObject.keys(sdkStreamMixin).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return sdkStreamMixin[k]; }\n    });\n});\nObject.keys(splitStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return splitStream[k]; }\n    });\n});\nObject.keys(streamTypeCheck).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return streamTypeCheck[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.sdkStreamMixin = void 0;\nconst fetch_http_handler_1 = require(\"@smithy/fetch-http-handler\");\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst util_hex_encoding_1 = require(\"@smithy/util-hex-encoding\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nconst ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED = \"The stream has already been transformed.\";\nconst sdkStreamMixin = (stream) => {\n    if (!isBlobInstance(stream) && !(0, stream_type_check_1.isReadableStream)(stream)) {\n        const name = stream?.__proto__?.constructor?.name || stream;\n        throw new Error(`Unexpected stream implementation, expect Blob or ReadableStream, got ${name}`);\n    }\n    let transformed = false;\n    const transformToByteArray = async () => {\n        if (transformed) {\n            throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n        }\n        transformed = true;\n        return await (0, fetch_http_handler_1.streamCollector)(stream);\n    };\n    const blobToWebStream = (blob) => {\n        if (typeof blob.stream !== \"function\") {\n            throw new Error(\"Cannot transform payload Blob to web stream. Please make sure the Blob.stream() is polyfilled.\\n\" +\n                \"If you are using React Native, this API is not yet supported, see: https://react-native.canny.io/feature-requests/p/fetch-streaming-body\");\n        }\n        return blob.stream();\n    };\n    return Object.assign(stream, {\n        transformToByteArray: transformToByteArray,\n        transformToString: async (encoding) => {\n            const buf = await transformToByteArray();\n            if (encoding === \"base64\") {\n                return (0, util_base64_1.toBase64)(buf);\n            }\n            else if (encoding === \"hex\") {\n                return (0, util_hex_encoding_1.toHex)(buf);\n            }\n            else if (encoding === undefined || encoding === \"utf8\" || encoding === \"utf-8\") {\n                return (0, util_utf8_1.toUtf8)(buf);\n            }\n            else if (typeof TextDecoder === \"function\") {\n                return new TextDecoder(encoding).decode(buf);\n            }\n            else {\n                throw new Error(\"TextDecoder is not available, please make sure polyfill is provided.\");\n            }\n        },\n        transformToWebStream: () => {\n            if (transformed) {\n                throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n            }\n            transformed = true;\n            if (isBlobInstance(stream)) {\n                return blobToWebStream(stream);\n            }\n            else if ((0, stream_type_check_1.isReadableStream)(stream)) {\n                return stream;\n            }\n            else {\n                throw new Error(`Cannot transform payload to web stream, got ${stream}`);\n            }\n        },\n    });\n};\nexports.sdkStreamMixin = sdkStreamMixin;\nconst isBlobInstance = (stream) => typeof Blob === \"function\" && stream instanceof Blob;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.sdkStreamMixin = void 0;\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst util_buffer_from_1 = require(\"@smithy/util-buffer-from\");\nconst stream_1 = require(\"stream\");\nconst sdk_stream_mixin_browser_1 = require(\"./sdk-stream-mixin.browser\");\nconst ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED = \"The stream has already been transformed.\";\nconst sdkStreamMixin = (stream) => {\n    if (!(stream instanceof stream_1.Readable)) {\n        try {\n            return (0, sdk_stream_mixin_browser_1.sdkStreamMixin)(stream);\n        }\n        catch (e) {\n            const name = stream?.__proto__?.constructor?.name || stream;\n            throw new Error(`Unexpected stream implementation, expect Stream.Readable instance, got ${name}`);\n        }\n    }\n    let transformed = false;\n    const transformToByteArray = async () => {\n        if (transformed) {\n            throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n        }\n        transformed = true;\n        return await (0, node_http_handler_1.streamCollector)(stream);\n    };\n    return Object.assign(stream, {\n        transformToByteArray,\n        transformToString: async (encoding) => {\n            const buf = await transformToByteArray();\n            if (encoding === undefined || Buffer.isEncoding(encoding)) {\n                return (0, util_buffer_from_1.fromArrayBuffer)(buf.buffer, buf.byteOffset, buf.byteLength).toString(encoding);\n            }\n            else {\n                const decoder = new TextDecoder(encoding);\n                return decoder.decode(buf);\n            }\n        },\n        transformToWebStream: () => {\n            if (transformed) {\n                throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n            }\n            if (stream.readableFlowing !== null) {\n                throw new Error(\"The stream has been consumed by other callbacks.\");\n            }\n            if (typeof stream_1.Readable.toWeb !== \"function\") {\n                throw new Error(\"Readable.toWeb() is not supported. Please ensure a polyfill is available.\");\n            }\n            transformed = true;\n            return stream_1.Readable.toWeb(stream);\n        },\n    });\n};\nexports.sdkStreamMixin = sdkStreamMixin;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.splitStream = splitStream;\nasync function splitStream(stream) {\n    if (typeof stream.stream === \"function\") {\n        stream = stream.stream();\n    }\n    const readableStream = stream;\n    return readableStream.tee();\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.splitStream = splitStream;\nconst stream_1 = require(\"stream\");\nconst splitStream_browser_1 = require(\"./splitStream.browser\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nasync function splitStream(stream) {\n    if ((0, stream_type_check_1.isReadableStream)(stream) || (0, stream_type_check_1.isBlob)(stream)) {\n        return (0, splitStream_browser_1.splitStream)(stream);\n    }\n    const stream1 = new stream_1.PassThrough();\n    const stream2 = new stream_1.PassThrough();\n    stream.pipe(stream1);\n    stream.pipe(stream2);\n    return [stream1, stream2];\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isBlob = exports.isReadableStream = void 0;\nconst isReadableStream = (stream) => typeof ReadableStream === \"function\" &&\n    (stream?.constructor?.name === ReadableStream.name || stream instanceof ReadableStream);\nexports.isReadableStream = isReadableStream;\nconst isBlob = (blob) => {\n    return typeof Blob === \"function\" && (blob?.constructor?.name === Blob.name || blob instanceof Blob);\n};\nexports.isBlob = isBlob;\n"],"names":[],"sourceRoot":""}